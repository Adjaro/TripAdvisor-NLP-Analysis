{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les nombres et calculer les pages\n",
    "def extraire_infos(texte):\n",
    "    \"\"\"\n",
    "    Extrait le nombre de commentaires par page, le nombre total de commentaires,\n",
    "    et calcule le nombre de pages à partir d'un texte donné.\n",
    "    \"\"\"\n",
    "    chiffres = [int(s) for s in re.findall(r'\\d+', texte)]\n",
    "    if len(chiffres) >= 2:\n",
    "        nb_commentaires_par_page = chiffres[1]  # Exemple : \"15\" (2e chiffre)\n",
    "        nb_total_commentaires = chiffres[-1]   # Exemple : \"747\" (dernier chiffre)\n",
    "        nb_pages = math.ceil(nb_total_commentaires / nb_commentaires_par_page)\n",
    "        return nb_commentaires_par_page, nb_total_commentaires, nb_pages\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Fonction pour scraper les avis d'une page\n",
    "def scraper_page(driver):\n",
    "    \"\"\"\n",
    "    Récupère les avis d'une seule page.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # Récupération des éléments sur la page\n",
    "    pseudos = driver.find_elements(By.XPATH, \"//span[@class='biGQs _P fiohW fOtGX']\")\n",
    "    titres = driver.find_elements(By.XPATH, \"//div[@class='biGQs _P fiohW qWPrE ncFvv fOtGX']\")\n",
    "    etoiles = driver.find_elements(By.XPATH, \"//div[@class='OSBmi J k']\")\n",
    "    nb_etoiles = [re.search(r'(\\d+),', etoile.get_attribute(\"textContent\")).group(1) for etoile in etoiles]\n",
    "    dates = [driver.execute_script(\"return arguments[0].childNodes[0].textContent;\", elem).strip() for elem in driver.find_elements(By.XPATH, \"//div[@class='aVuQn']\")]\n",
    "    experiences = driver.find_elements(By.XPATH, \"//span[@class='DlAxN']\")\n",
    "    reviews = driver.find_elements(By.XPATH, \"//div[@data-test-target='review-body']//span[@class='JguWG' and not(ancestor::div[contains(@class, 'csNQI')])]\")\n",
    "\n",
    "    for i in range(len(titres)):\n",
    "        avis = {\n",
    "            \"pseudo\": pseudos[i].text if i < len(pseudos) else \"\",\n",
    "            \"titre_review\": titres[i].text if i < len(titres) else \"\",\n",
    "            \"nb_etoiles\": nb_etoiles[i] if i < len(nb_etoiles) else \"\",\n",
    "            \"date\": dates[i] if i < len(dates) else \"\",\n",
    "            \"experience\": experiences[i].text if i < len(experiences) else \"\",\n",
    "            \"review\": reviews[i].text if i < len(reviews) else \"\"\n",
    "        }\n",
    "        data.append(avis)\n",
    "    return data\n",
    "\n",
    "# Fonction pour scraper les avis de toutes les pages\n",
    "def scraper_toutes_pages(driver, nb_pages):\n",
    "    \"\"\"\n",
    "    Scrape les avis de toutes les pages en utilisant la fonction `scraper_page`.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    actions = ActionChains(driver)\n",
    "    for page in range(1, nb_pages + 1):\n",
    "        print(f\"Scraping de la page {page}...\")\n",
    "        # Récupérer les données de la page actuelle\n",
    "        data = scraper_page(driver)\n",
    "        print(f\"Données collectées pour la page {page} : {len(data)} avis\")\n",
    "        all_data.extend(data)\n",
    "        # Navigation vers la page suivante\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            next_button = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//a[@aria-label='Page suivante']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "            \n",
    "            actions.move_to_element(next_button).click().perform()\n",
    "            \n",
    "            # Attendre qu'un élément clé de la page suivante apparaisse\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[@class='biGQs _P fiohW qWPrE ncFvv fOtGX']\"))\n",
    "            )\n",
    "            print(\"Page suivante chargée.\")\n",
    "        except Exception as e:\n",
    "            print(\"Erreur ou plus de pages :\", e)\n",
    "            break\n",
    "    return all_data\n",
    "\n",
    "# Tester les fonctions\n",
    "def test_scraping(driver, nbPages_texte):\n",
    "    \"\"\"\n",
    "    Teste l'ensemble du processus de scraping :\n",
    "    - Extraction d'informations sur les pages\n",
    "    - Scraping des avis sur toutes les pages\n",
    "    \"\"\"\n",
    "    # Étape 1 : Extraire les infos\n",
    "    nb_commentaires_par_page, nb_total_commentaires, nb_pages = extraire_infos(nbPages_texte)\n",
    "    print(f\"Commentaires par page : {nb_commentaires_par_page}\")\n",
    "    print(f\"Total commentaires : {nb_total_commentaires}\")\n",
    "    print(f\"Nombre de pages : {nb_pages}\")\n",
    "\n",
    "    # Étape 2 : Scraper les avis sur toutes les pages\n",
    "    if nb_pages:\n",
    "        all_data = scraper_toutes_pages(driver, nb_pages)\n",
    "        print(f\"Scraping terminé. Total d'avis collectés : {len(all_data)}\")\n",
    "        return all_data\n",
    "    else:\n",
    "        print(\"Erreur dans le calcul des pages.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page ouverte avec un User-Agent réaliste\n"
     ]
    }
   ],
   "source": [
    "# Service pour ChromeDriver\n",
    "# Modifier avec le bon chemin\n",
    "service = Service('C:/Users/Ihnhn/Desktop/M2 SISE/NLP/Projet/chromedriver.exe')\n",
    "# Step 3: Rotate user agents \n",
    "user_agents = [\n",
    "    # Add your list of user agents here\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "]\n",
    "# Configuration du navigateur\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"start-maximized\")\n",
    "#options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "# select random user agent\n",
    "user_agent = random.choice(user_agents)\n",
    "# pass in selected user agent as an argument\n",
    "options.add_argument(f'--user-agent={user_agent}')\n",
    "# Lancement du navigateur\n",
    "driver = uc.Chrome(options=options, service=service)\n",
    "\n",
    "# Ouvrez TripAdvisor\n",
    "#driver.get(\"https://www.tripadvisor.fr/Restaurant_Review-g187265-d3727154-Reviews-Les_Terrasses_de_Lyon-Lyon_Rhone_Auvergne_Rhone_Alpes.html\")\n",
    "driver.get(\"https://www.tripadvisor.fr/Restaurant_Review-g187265-d23110895-Reviews-Frazarin-Lyon_Rhone_Auvergne_Rhone_Alpes.html\")\n",
    "# Exécution de JavaScript pour rendre Selenium indétectable\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "time.sleep(3)\n",
    "click_cookies = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"button[id='onetrust-reject-all-handler']\"))).click()\n",
    "\n",
    "print(\"Page ouverte avec un User-Agent réaliste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbPages_texte = driver.find_element(\"xpath\", \"//div[@class='Ci']\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_scraping(driver, nbPages_texte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
