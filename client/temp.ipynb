{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from dateutil import parser\n",
    "from utils import database\n",
    "from model import models, schemas\n",
    "from functools import lru_cache\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create all tables in the database\n",
    "models.Base.metadata.create_all(bind=database.engine)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_month_mapping():\n",
    "    return {\n",
    "        'janvier': 'January', 'février': 'February', 'mars': 'March',\n",
    "        'avril': 'April', 'mai': 'May', 'juin': 'June', 'juillet': 'July',\n",
    "        'août': 'August', 'septembre': 'September', 'octobre': 'October',\n",
    "        'novembre': 'November', 'décembre': 'December'\n",
    "    }\n",
    "\n",
    "def concatener(lst):\n",
    "    return ', '.join(lst)\n",
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        fr_to_en = get_month_mapping()\n",
    "        day, month, year = date_str.split(' ')\n",
    "        month_en = fr_to_en[month.lower()]\n",
    "        date_en = f\"{day} {month_en} {year}\"\n",
    "        return parser.parse(date_en, dayfirst=True)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing date {date_str}: {e}\")\n",
    "\n",
    "def get_value(data, key1, key2):\n",
    "    return data.get(key1) or data.get(key2)\n",
    "\n",
    "# Load a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Get the list of JSON files\n",
    "def get_data_list(data_dir='./data'):\n",
    "    return [f for f in os.listdir(data_dir) if f.endswith('.json')]\n",
    "\n",
    "def apply_concatener_if_list(value):\n",
    "    if isinstance(value, list):\n",
    "        return concatener(value)\n",
    "    return value\n",
    "# Insert data into the database (optimized for batches)\n",
    "def insert_data(dict_data):\n",
    "    db = database.SessionLocal()\n",
    "    try:\n",
    "        # Insert location\n",
    "        id_location = str(uuid.uuid4())\n",
    "        dict_location = {\n",
    "            'id_location': id_location,\n",
    "            'longitude': dict_data['longitude'],\n",
    "            'latitude': dict_data['latitude'],\n",
    "            'adresse': dict_data['adresse']\n",
    "        }\n",
    "        location = models.DimLocation(**schemas.DimLocation(**dict_location).model_dump())\n",
    "        db.add(location)\n",
    "\n",
    "        print(dict_data['nom'])\n",
    "        # Insert restaurant\n",
    "        id_restaurant = str(uuid.uuid4())\n",
    "        dict_restaurant = {\n",
    "            'id_restaurant': id_restaurant,\n",
    "            'nom': dict_data['nom'],\n",
    "            'classement': dict_data['classement'],\n",
    "            'horaires': apply_concatener_if_list(dict_data['horaires']),\n",
    "            'note_globale': dict_data['note_globale'],\n",
    "            'note_cuisine': dict_data['note_cuisine'],\n",
    "            'note_service': dict_data['note_service'],\n",
    "            'note_rapportqualiteprix': dict_data['note_rapportqualiteprix'],\n",
    "            'note_ambiance': dict_data['note_ambiance'],\n",
    "            'infos_pratiques': apply_concatener_if_list(dict_data['infos_pratiques']),\n",
    "            'repas': apply_concatener_if_list(dict_data['repas']),\n",
    "            'fourchette_prix': dict_data['fourchette_prix'],\n",
    "            'fonctionnalites': apply_concatener_if_list(dict_data['fonctionnalités']),\n",
    "            'type_cuisines': apply_concatener_if_list(dict_data['type_cuisines']),\n",
    "            'nb_avis': dict_data['nb_avis'],\n",
    "            'nbExcellent': dict_data['nbExcellent'],\n",
    "            'nbTresbon': get_value(dict_data, 'nbTrèsBon', 'nbTrèsbon'),\n",
    "            'nbMoyen': dict_data['nbMoyen'],\n",
    "            'nbMediocre': dict_data['nbMédiocre'],\n",
    "            'nbHorrible': dict_data['nbHorrible'],\n",
    "            'id_location': id_location\n",
    "        }\n",
    "        restaurant = models.DimRestaurant(**schemas.DimRestaurant(**dict_restaurant).model_dump())\n",
    "        db.add(restaurant)\n",
    "\n",
    "        # Prepare entries for reviews and dates\n",
    "        avis_entries = []\n",
    "        date_entries = []\n",
    "\n",
    "        for avis in dict_data['avis']:\n",
    "            # Insert date\n",
    "            id_date = str(uuid.uuid4())\n",
    "            date_temp = parse_date(avis['date'])\n",
    "            jour_temp, mois_temp, annee_temp = avis['date'].split(' ')\n",
    "            dict_time = {\n",
    "                'id_date': id_date,\n",
    "                'date': date_temp,\n",
    "                'mois': str(mois_temp),\n",
    "                'annee': str(annee_temp),\n",
    "                'jour': str(jour_temp),\n",
    "            }\n",
    "            date_entry = models.DimDate(**schemas.DimDate(**dict_time).model_dump())\n",
    "            date_entries.append(date_entry)\n",
    "\n",
    "            # Insert review\n",
    "            id_avis = str(uuid.uuid4())\n",
    "            dict_avis = {\n",
    "                'id_avis': id_avis,\n",
    "                'id_restaurant': id_restaurant,\n",
    "                'id_date': id_date,\n",
    "                'nb_etoiles': avis['nb_etoiles'],\n",
    "                'experience': avis['experience'],\n",
    "                'review': avis['review'],\n",
    "                'titre_avis': avis['titre_review']\n",
    "            }\n",
    "            avis_entry = models.FaitAvis(**schemas.FaitAvis(**dict_avis).model_dump())\n",
    "            avis_entries.append(avis_entry)\n",
    "\n",
    "        # Execute batch insertions\n",
    "        db.add_all(date_entries)\n",
    "        db.add_all(avis_entries)\n",
    "        db.commit()\n",
    "        logger.info(f\"Data inserted for {dict_data['nom']}\")\n",
    "        print(f\"Data inserted for {dict_data['nom']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur : {e}\")\n",
    "        print(f\"Erreur : {e}\")\n",
    "        db.rollback()\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# Load all JSON files into memory\n",
    "def load_all_json(data_dir='./data'):\n",
    "    data_list = []\n",
    "    for file in get_data_list(data_dir):\n",
    "        data = read_json_file(f'{data_dir}/{file}')\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "# Insert data from JSON files\n",
    "def insert_json_data(data_dir='./data'):\n",
    "    all_data = load_all_json(data_dir)\n",
    "    db = database.SessionLocal()\n",
    "    try:\n",
    "        for data in all_data:\n",
    "            insert_data(data)\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# # Start the import process\n",
    "# if __name__ == \"__main__\":\n",
    "#     insert_json_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
